docker.enabled = true
docker.runOptions = '-u $(id -u):$(id -g)'

params {
    sample_id = ""
    output_basename = ""
    input_fastq_reads =  ""
    is_paired_end = ""
    // bam input processing
    input_alignment_reads = ""
    max_reads = 200000
    line_filter = "^@RG"

    // cutadapt specific
    is_paired_end = ""
    cutadapt_r1_adapter = ""
    cutadapt_r2_adapter = ""
    cutadapt_min_len = ""
    cutadapt_quality_base = ""
    cutadapt_quality_cutoff = ""
    cutadapt_min_read_len = 20
    
    reference = "" 
    threads = 8
    ram = ""
    // STAR-specific
    genomeDir = ""
    readFilesCommand = ""
    readFilesManifest = ""
    alignInsertionFlush = "None"
    alignIntronMax = 1000000
    alignMatesGapMax = 1000000
    alignSJDBoverhangMin = 1
    alignSJoverhangMin = 8
    alignSJstitchMismatchNmax = "5 -1 5 5"
    alignSoftClipAtReferenceEnds = "Yes"
    alignSplicedMateMapLmin = 0
    alignSplicedMateMapLminOverLmate = 0.5
    chimJunctionOverhangMin = 10
    chimMainSegmentMultNmax = 1
    chimMultimapNmax = 50
    chimMultimapScoreRange = 1
    chimNonchimScoreDropMin = 20
    chimOutJunctionFormat = 1
    chimOutType = "Junctions WithinBAM SoftClip"
    chimScoreDropMax = 30
    chimScoreJunctionNonGTAG = -1
    chimScoreSeparation = 1
    chimSegmentMin = 10
    chimSegmentReadGapMax = 3
    genomeLoad = "NoSharedMemory"
    limitSjdbInsertNsj = 1200000
    outFilterIntronMotifs = "None"
    outFilterMatchNminOverLread = 0.33
    outFilterMismatchNmax = 999
    outFilterMismatchNoverLmax = 0.1
    outFilterMultimapNmax = 50
    outFilterScoreMinOverLread = 0.33
    outFilterType = "BySJout"
    outReadsUnmapped = "None"
    outSAMattributes = "NH HI AS nM NM ch"
    outSAMstrandField = "intronMotif"
    outSAMtype = "BAM Unsorted"
    outSAMunmapped = "Within"
    peOverlapMMp = 0.01
    peOverlapNbasesMin = 10
    quantMode = "TranscriptomeSAM GeneCounts"
    runThreadN = 16
    twopassMode = "Basic"
    // misc
    max_memory = "128 GB"
    max_time = "12h"
    max_cpus = 96
    outdir = "./"
}

includeConfig 'conf/base.config'
includeConfig 'conf/kids_first.config'

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
// from: https://github.com/nf-core/sarek/blob/master/nextflow.config
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}